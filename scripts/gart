#!/bin/bash

# Copyright 2020-2023 Alibaba Group Holding Limited.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This script provides utility functions to set up and launch the GART system with various components
# including PostgreSQL, MySQL, Kafka, ZooKeeper, and others depending on the specified role.

db_host="127.0.0.1"
db_port=5432
db_name="ldbc"
db_user=
db_password=
rgmapping_file="schema/rgmapping-ldbc.yaml"
v6d_sock="/var/run/vineyard.sock"
v6d_size="750G"
etcd_endpoint="http://127.0.0.1:2379"
etcd_prefix="gart_meta_"
kafka_server="127.0.0.1:9092"
subgraph_num=1
use_debezium=true
db_type="postgresql"
enable_bulkload=false
role="all"
start_slot=
num_slot=
rg_from_etcd=false
k8s_mode=false
subgraph_id=0
debug=
debug_writer=false
debug_converter=false

set_port=false

print_arguments() {
    printf "Arguments:\n"
    printf "    %-20s %s\n" "db-type:" "$db_type"
    printf "    %-20s %s\n" "db-host:" "$db_host"
    printf "    %-20s %s\n" "db-port:" "$db_port"
    printf "    %-20s %s\n" "db-name:" "$db_name"
    printf "    %-20s %s\n" "db-user:" "$db_user"
    printf "    %-20s %s\n" "db-password:" "$db_password"
    printf "    %-20s %s\n" "rgmapping-file:" "$rgmapping_file"
    printf "    %-20s %s\n" "rg-from-etcd:" "$rg_from_etcd"
    printf "    %-20s %s\n" "v6d-sock:" "$v6d_sock"
    printf "    %-20s %s\n" "v6d-size:" "$v6d_size"
    printf "    %-20s %s\n" "use-debezium:" "$use_debezium"
    printf "    %-20s %s\n" "enable-bulkload:" "$enable_bulkload"
    printf "    %-20s %s\n" "etcd-endpoint:" "$etcd_endpoint"
    printf "    %-20s %s\n" "etcd-prefix:" "$etcd_prefix"
    printf "    %-20s %s\n" "kafka-server:" "$kafka_server"
    printf "    %-20s %s\n" "subgraph-num:" "$subgraph_num"
    printf "    %-20s %s\n" "role:" "$role"
    printf "    %-20s %s\n" "start-slot:" "$start_slot"
    printf "    %-20s %s\n" "num-slot:" "$num_slot"
    printf "    %-20s %s\n" "k8s-mode:" "$k8s_mode"
    printf "    %-20s %s\n" "debug:" "${debug[*]}"
}


# Function to normalize boolean inputs (1/0, yes/no, true/false) to true or false
normalize_boolean() {
    case "$(echo "$1" | tr '[:upper:]' '[:lower:]')" in
        1 | yes | true)
            echo "true"
            ;;
        0 | no | false)
            echo "false"
            ;;
        *)
            echo "Error: Invalid boolean value '$1'." >&2
            exit 1
            ;;
    esac
}

# check file path
make_absolute_path() {
    local path=$1
    if [[ ! $path = /* ]]; then
        path=$(readlink -f "$path" 2>/dev/null || pwd -P)
    fi
    echo "$path"
}

# Function to display the help message
show_help() {
    cat << EOF
Usage: $0 [options]
Options:
  -h, --help:                    Show this help message and exit.
      --db-type:                 Type of data source: postgresql, mysql (default: postgresql).
  -d, --db-host:                 Database host (default: 127.0.0.1).
      --db-port:                 Database port (default: 3306 for MySQL, 5432 for PostgreSQL).
  -b, --db-name:                 Database name (default: ldbc).
  -u, --db-user:                 Database user.
  -p, --db-password:             Database password.
  -r, --rgmapping-file:          RGMapping file path (default: schema/rgmapping-ldbc.yaml).
      --rg-from-etcd:            Whether to read RG mapping from etcd (default: false).
      --v6d-sock:                Vineyard socket path (default: /var/run/vineyard.sock).
      --v6d-size:                Vineyard size (default: 110G).
      --use-debezium:            Whether to use Debezium to parse txn logs (default: true).
      --enable-bulkload:         Whether to enable bulkload (default: false).
  -e, --etcd-endpoint:           Etcd endpoint (default: http://127.0.0.1:2379).
      --etcd-prefix:             Etcd metadata prefix (default: gart_meta_).
  -k, --kafka-server:            Kafka bootstrap server (default: 127.0.0.1:9092).
      --subgraph-num:            Number of subgraphs (default: 1).
      --role:                    Role when running this script: capturer, converter, writer, or all (default: all).
      --start-slot:              The start slot of subgraph on this machine.
      --num-slot:                The number of slots on this machine.
      --k8s-mode:                Whether running in k8s mode (default: false).
      --debug:                   Specify components to debug. Pass as a comma-separated list.
                                 Examples: '--debug=writer', '--debug=converter,writer' (default: '').
EOF
}

####################### Parse Arguments #######################
parse_arguments() {
    local VALID_ARGS=$(getopt -o d:b:u:p:r:t:e:k:h? --long db-host:,db-name:,db-port:,db-user:,db-password:,rgmapping-file:,v6d-sock:,v6d-size:,use-debezium:,db-type:,enable-bulkload:,etcd-endpoint:,etcd-prefix:,kafka-server:,subgraph-num:,subgraph-id:,role:,debug:,start-slot:,num-slot:,k8s-mode:,rg-from-etcd:,help -- "$@")
    if [[ $? -ne 0 ]]; then
        exit 1;
    fi

    eval set -- "$VALID_ARGS"

    while [ : ]; do
        case "$1" in
            -d | --db-host)
                db_host=$2
                shift 2
                ;;
                --db-port)
                db_port=$2
                shift 2
                set_port=true
                ;;
            -b | --db-name)
                db_name=$2
                shift 2
                ;;
            -u | --db-user)
                db_user=$2
                shift 2
                ;;
            -p | --db-password)
                db_password=$2
                shift 2
                ;;
            -r | --rgmapping-file)
                rgmapping_file=$(make_absolute_path "$2")
                shift 2
                ;;
                --v6d-sock)
                v6d_sock=$(make_absolute_path "$2")
                shift 2
                ;;
                --v6d-size)
                v6d_size=$2
                shift 2
                ;;
                --use-debezium)
                use_debezium=$(normalize_boolean "$2")
                shift 2
                ;;
                --db-type)
                db_type=$(echo "$2" | awk '{print tolower($0)}')
                shift 2
                ;;
                --enable-bulkload)
                enable_bulkload=$(normalize_boolean "$2")
                shift 2
                ;;
            -e | --etcd-endpoint)
                etcd_endpoint=$2
                shift 2
                ;;
                --etcd-prefix)
                etcd_prefix=$2
                shift 2
                ;;
            -k | --kafka-server)
                kafka_server=$2
                shift 2
                ;;
                --subgraph-num)
                subgraph_num=$2
                shift 2
                ;;
                --subgraph-id)
                subgraph_id=$2
                shift 2
                ;;
                --role)
                role=$(echo "$2" | awk '{print tolower($0)}')
                shift 2
                ;;
                --debug)
                debug=$(echo "$2" | awk '{print tolower($0)}')
                IFS=',' read -r -a debug <<< "$debug"
                shift 2
                ;;
                --start-slot)
                start_slot=$2
                shift 2
                ;;
                --num-slot)
                num_slot=$2
                shift 2
                ;;
                --rg-from-etcd)
                rg_from_etcd=$(normalize_boolean "$2")
                shift 2
                ;;
                --k8s-mode)
                k8s_mode=$(normalize_boolean "$2")
                shift 2
                ;;
            -h | --help | ?)
                show_help
                exit 0
                ;;
            --)
                shift;
                break
                ;;
        esac
    done

    # set default port
    if [ "$set_port" != "true" ] && [ "$db_type" == "mysql" ]; then
        db_port=3306
    fi
}

set_debug() {
    if [ -n "$debug" ]; then
        for component in "${debug[@]}"; do
            case "$component" in
                # capturer)
                #     debug_capturer=true
                #     ;;
                converter)
                    debug_converter=true
                    ;;
                writer)
                    debug_writer=true
                    ;;
                *)
                    echo "Invalid debug component: $component"
                    exit 1
                    ;;
            esac
        done
    fi
}

check_arguments() {
    case "$db_type" in
        mysql|postgresql)
            # Valid database types, no action needed
            ;;
        *)
            echo "Invalid value for 'db_type': $db_type"
            exit 1
            ;;
    esac

    if [ "$use_debezium" != "true" ] && [ "$db_type" != "mysql" ]; then
        echo "Maxwell only supports MySQL"
        exit 1
    fi

    case "$role" in
        all|capturer|converter|writer)
            # Valid roles, no action needed
            ;;
        *)
            echo "Invalid value for 'role': $role"
            exit 1
            ;;
    esac
}

check_file() {
    local prefix=$1
    local file=$2
    if [ ! -f "$file" ]; then
        echo "$1 file $file does not exist."
        exit 1
    fi
}

check_environment() {
    local env_unset=true
    if [ "$role" == "all" ] || [ "$role" == "capturer" ]; then
        env_unset=false
        if [ -n "$KAFKA_HOME" ]; then
            echo "    KAFKA_HOME: $KAFKA_HOME"
        else
            echo "KAFKA_HOME is empty, please set the environment variable KAFKA_HOME"
            env_unset=true
        fi

        if [ "$use_debezium" != "true" ] ; then
            if [ -n "$MAXWELL_HOME" ]; then
                echo "    MAXWELL_HOME: $MAXWELL_HOME"
            else
                echo "MAXWELL_HOME is empty, please set the environment variable MAXWELL_HOME"
                env_unset=true
            fi
        fi

        if [ "$env_unset" == "true" ]; then
            exit 1
        fi
    fi
}

allocate_slot() {
    # Set defaults or exit based on conditions
    if [[ $role == "all" ]]; then
        start_slot=0
        num_slot=$subgraph_num
    elif [[ $role == "writer" ]]; then
        # Check if either start_slot or num_slot is unset or empty
        if [[ -z $start_slot || -z $num_slot ]]; then
            # If both are unset or empty, set to defaults
            if [[ -z $start_slot && -z $num_slot ]]; then
                start_slot=0
                num_slot=$subgraph_num
            else
                # If only one is set, it's an error
                echo "Please set both start-slot and num-slot"
                exit 1
            fi
        else
            # Additional log for clarity when both slots are provided
            echo "    Run Writer as given slot info"
        fi
    fi
}

# Check database connection for PostgreSQL
check_postgresql_connection() {
    PGPASSWORD=$db_password psql -h "$db_host" -p "$db_port" -U "$db_user" -d "$db_name" -c "\q"
    if [ $? -eq 0 ]; then
        echo "Successfully connected to PostgreSQL database."
    else
        echo "Could not connect to PostgreSQL database."
    fi
}

# Check database connection for MySQL
check_mysql_connection() {
    mysql --host="$db_host" --port="$db_port" --user="$db_user" --password="$db_password" --database="$db_name" -e "QUIT"
    if [ $? -eq 0 ]; then
        echo "Successfully connected to MySQL database."
    else
        echo "Could not connect to MySQL database."
    fi
}

prepare_args() {
    parse_arguments "$@"
    set_debug
    check_arguments
    check_environment
    if [ "$rg_from_etcd" != "true" ]; then
        check_file "RGMapping" "$rgmapping_file"
    fi
    allocate_slot

    print_arguments
    if [ $role == "all" ]; then
        if [ "$db_type" == "postgresql" ]; then
            check_postgresql_connection
        elif [ "$db_type" == "mysql" ]; then
            check_mysql_connection
        fi
    fi
}

extract_table_schema() {
    echo "Start extracting schema"
    local extract_cmd="PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python ./scripts/extract_table_schema.py \
        --host $db_host --port $db_port --db $db_name \
        --user $db_user --password $db_password --db_type $db_type\
        --rgmapping_file $rgmapping_file --etcd_endpoint $etcd_endpoint \
        --etcd_prefix $etcd_prefix --rg_mapping_from_etcd $rg_from_etcd"

    local num_row=$(eval "$extract_cmd")

    # not a number
    if [[ ! $num_row =~ ^[0-9]+$ ]]; then
        echo "Extract schema command: $extract_cmd"
        echo "Error in extracting schema from database: $num_row"
        exit 1
    fi

    if [ $num_row -eq -1 ]; then
        echo "Extract schema command: $extract_cmd"
        echo "Failed to extract schema from database, please check the status of database and database info you provide."
        exit 1
    elif [ $num_row -eq 0 ] && [ "$enable_bulkload" == "true" ]; then
        echo "No tuples found in the database, skip bulk load"
        enable_bulkload=false
    fi
}

clean_previous_gart() {
    if [ "$role" == "all" ]; then
        ##################### Stop Previous GART ######################
        echo "Stop previous GART"
        ./stop-gart --kill-v6d-sock $v6d_sock

        ####################### Clean Etcd #######################
        echo "Clean etcd"
        etcdctl --endpoints=$etcd_endpoint del --prefix $etcd_prefix > /dev/null 2>&1
    fi

    ################### Bulk Load Initialize ######################
    if [ "$role" == "all" ] || [ "$role" == "capturer" ]; then
        if [ "$use_debezium" == "true" ] && [ "$enable_bulkload" == "true" ]; then
            rm /tmp/connect.offsets 1 > /dev/null 2>&1
            echo "Remove /tmp/connect.offsets for bulk load"
        fi
    fi
}

prepare_args "$@"
clean_previous_gart

declare -A pids     # array to store pids and comments

####################### Vineyard #######################
if [ "$role" == "all" ] || [ "$role" == "writer" ]; then
    echo "Start Vineyard"
    if ! pgrep -f "vineyardd .* $v6d_sock" > /dev/null 2>&1; then
        if [ -e "$v6d_sock" ]; then
            echo "Remove existing vineyard socket $v6d_sock"
            rm $v6d_sock
        fi
        echo "Start to launch vineyardd on $v6d_sock"
        # TODO: etcd_cmd user for PostgreSQL Extension
        vineyardd --socket $v6d_sock --size $v6d_size --etcd_endpoint $etcd_endpoint  --norpc > /dev/null 2>&1 &
        pids["Vineyard"]=$!
        sleep 5
        if [ ! -e "$v6d_sock" ] || [ ! -S "$v6d_sock" ]; then
            echo "Failed to launch vineyardd"
            exit 1
        fi
    fi
fi

####################### Etcd #######################
if [ "$k8s_mode" != "true" ]  && { [ "$role" == "capturer" ] || [ "$role" == "converter" ]; }; then
    echo "Start to launch Etcd by role $role"
    if ! pgrep -f "etcd .*$etcd_endpoint" > /dev/null 2>&1; then
        echo "Start to launch etcd on $etcd_endpoint"
        export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
        etcd_status=$(
        ./scripts/launch_etcd.py --etcd_endpoint $etcd_endpoint
        )
        if [ $etcd_status -eq 1 ]; then
            echo "Etcd is launched successfully"
        else
            echo "Failed to launch etcd"
            exit 1
        fi
    else
        echo "Etcd is already running"
    fi
fi

####################### Extract Schema #######################
if [ "$role" == "all" ] || [ "$role" == "capturer" ] || { [ "$k8s_mode" == "true" ] && [ "$role" == "converter" ]; }; then
    extract_table_schema
fi

####################### Capturer: Zookeeper and Kafka #######################
if [ "$role" == "all" ] || [ "$role" == "capturer" ]; then
    KAFKA_BIN=$KAFKA_HOME/bin
    KAFKA_CONFIG=$KAFKA_HOME/config
    KAFKA_LOG=$KAFKA_HOME/logs/kafkaServer.out

    # write Kafka config according to graph schema
    PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python \
    ./scripts/update_kafka_config_file.py --etcd_endpoint $etcd_endpoint --etcd_prefix $etcd_prefix \
                                        --kafka_endpoint $kafka_server --db_type $db_type --db_host $db_host --db_port $db_port \
                                        --db_user $db_user --db_password $db_password --db_name $db_name --enable_bulkload $enable_bulkload

    echo "Start Zookeeper and Kafka"
    $KAFKA_BIN/zookeeper-server-start.sh -daemon $KAFKA_CONFIG/zookeeper.properties
    # pids["Zookeeper"]=$!
    sleep 20
    # sleep 20 to avoid https://stackoverflow.com/questions/39759071/error-while-starting-kafka-broker

    # Checking if the Zookeeper process is running
    if ps -ef | grep -v grep | grep zookeeper.server > /dev/null; then
        echo "Zookeeper process is running."
    else
        echo "Zookeeper process is NOT running. Wait for retrying."
    fi

    $KAFKA_BIN/kafka-server-start.sh -daemon $KAFKA_CONFIG/server.properties

    # pids["Kafka"]=$!
    sleep 8
    # check if Kafka is started
    if grep -q "started" $KAFKA_LOG; then
        echo "Kafka log shows successful startup."
    else
        echo "Kafka log does not indicate successful startup. Please check $KAFKA_LOG for details. Wait for retrying."
    fi


    # check Kafka failure
    for i in {1..3}
    do
        if grep -q "ERROR" $KAFKA_LOG; then
            if [ $i -ne 1 ]; then
                echo "File $KAFKA_LOG contains ERROR, waiting for cleanning"
                sleep 10
            fi
            $KAFKA_BIN/zookeeper-server-start.sh -daemon $KAFKA_CONFIG/zookeeper.properties
            sleep 3
            # Checking if the Zookeeper process is running
            if ps -ef | grep -v grep | grep zookeeper.server; then
                echo "Zookeeper process is running."
            else
                echo "Zookeeper process is NOT running. Wait for retrying."
            fi


            $KAFKA_BIN/kafka-server-start.sh -daemon $KAFKA_CONFIG/server.properties
            sleep 5
            if grep -q "started" $KAFKA_LOG; then
                echo "Kafka log shows successful startup."
            else
                echo "Kafka log does not indicate successful startup. Please check $KAFKA_LOG for details. Wait for retrying."
            fi

        else
            break
        fi
        if [ $i -eq 3 ]; then
            echo "Kafka: Reached max attempts, ERROR found"
            ./stop-gart --kill-v6d-sock $v6d_sock --is-abnormal
            exit 1
        fi
    done

    echo "    Clean topics: binlog & unified_log"
    $KAFKA_BIN/kafka-topics.sh --delete --topic 'binlog.*' --bootstrap-server 127.0.0.1:9092 > /dev/null 2>&1
    $KAFKA_BIN/kafka-topics.sh --delete --topic unified_log --bootstrap-server 127.0.0.1:9092 > /dev/null 2>&1

    sleep 2

    #TODO: hard code: replication-factor

    echo "    Create topic: binlog"
    $KAFKA_BIN/kafka-topics.sh --create --topic binlog --bootstrap-server 127.0.0.1:9092 --partitions 1 --replication-factor 1 > /dev/null 2>&1

    echo "    Create topic: unified_log"
    $KAFKA_BIN/kafka-topics.sh --create --topic unified_log --bootstrap-server 127.0.0.1:9092 --partitions 1 --replication-factor 1 > /dev/null 2>&1
    # $KAFKA_BIN/kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --list
fi


####################### Capturer: Maxwell #######################
if [ "$role" == "all" ] || [ "$role" == "capturer" ]; then
    if [ "$use_debezium" != "true" ]; then
        MAXWELL_BIN=$MAXWELL_HOME/bin

        echo "Start Maxwell"
        $MAXWELL_BIN/maxwell --host=$db_host --user=$db_user --password=$db_password --producer=kafka --kafka.bootstrap.servers=127.0.0.1:9092 --kafka_topic=binlog > /dev/null 2>&1 &

        pids["Maxwell"]=$!
        sleep 3
        process_count=$(
            ps aux | grep '[m]axwell.Maxwell' | wc -l | awk '{print $1}'
        )
        if [ $process_count -gt 0 ]; then
            export ETCDCTL_API=3
            etcd_prefix=$etcd_prefix
            etcd_key=$etcd_prefix"capturer_is_up"
            etcdctl --endpoints=$etcd_endpoint put $etcd_key "True"
        fi
    fi
fi

####################### Capturer: Debezium #######################
if [ "$role" == "all" ] || [ "$role" == "capturer" ]; then
# TODO(wanglei): add distributed deployment of debezium
    if [ "$use_debezium" == "true" ]; then
        unset CLASSPATH
        echo "Start Debezium"
        if [ "$db_type" == "mysql" ]; then
            echo "    Start Debezium connector for MySQL"
            $KAFKA_BIN/connect-standalone.sh $KAFKA_CONFIG/connect-standalone.properties $KAFKA_CONFIG/connect-debezium-mysql.properties > /dev/null 2>&1 &
        elif [ "$db_type" == "postgresql" ]; then
            echo "    Start Debezium connector for PostgreSQL"
            $KAFKA_BIN/connect-standalone.sh $KAFKA_CONFIG/connect-standalone.properties $KAFKA_CONFIG/connect-debezium-postgresql.properties > /dev/null 2>&1 &
        fi
        pids["Debezium"]=$!
        sleep 5
        process_count=$(
            ps aux | grep '[d]ebezium-api' | wc -l | awk '{print $1}'
        )
        if [ $process_count -gt 0 ]; then
            export ETCDCTL_API=3
            etcd_prefix=$etcd_prefix
            etcd_key=$etcd_prefix"capturer_is_up"
            etcdctl --endpoints=$etcd_endpoint put $etcd_key "True"
        fi
    fi
fi

####################### Converter #######################
if [ "$role" == "all" ] || [ "$role" == "converter" ]; then
    CONVENTER_HOME=./converter
    echo "Start Converter"
    # For bool flags, = is necessary,
    # since --enable_bulkload will be parsed as --enable_bulkload=true,
    # and --no_enable_bulkload will be parsed as --enable_bulkload=false
    converter_cmd=
    if [ "$use_debezium" == "true" ]; then
        converter_cmd="$CONVENTER_HOME/binlog_convert_debezium \
            --etcd_endpoint $etcd_endpoint \
            --etcd_prefix $etcd_prefix \
            --read_kafka_broker_list $kafka_server \
            --write_kafka_broker_list $kafka_server \
            --subgraph_num $subgraph_num --logs_per_epoch 10000 \
            --enable_bulkload=$enable_bulkload"
    else
        converter_cmd="$CONVENTER_HOME/binlog_convert_maxwell \
            --etcd_endpoint $etcd_endpoint \
            --etcd_prefix $etcd_prefix \
            --read_kafka_broker_list $kafka_server \
            --write_kafka_broker_list $kafka_server \
            --subgraph_num $subgraph_num --logs_per_epoch 10000"
    fi

    if $debug_converter; then
        echo "Debug Converter: ${converter_cmd} &"
    else
        echo "    Use Debezium converter"
        eval "${converter_cmd} &"
        pids["Converter"]=$!
        sleep 2
    fi

fi

####################### Writer (VEGITO) #######################
if [[ "$role" == "all" ]] || { [[ "$role" == "writer" ]] && [ "$k8s_mode" != "true" ]; }; then
    WRITER_HOME=./vegito

    for ((i=$start_slot; i<$start_slot + $num_slot; i++)); do
        vegito_cmd="$WRITER_HOME/vegito --v6d_ipc_socket $v6d_sock \
            --etcd_endpoint $etcd_endpoint --meta_prefix $etcd_prefix \
            --kafka_broker_list $kafka_server \
            --subgraph_num $subgraph_num --subgraph_id $i"

        if $debug_writer; then
            echo "Debug Writer $i: ${vegito_cmd} &"
        else
            echo "Start Writer $i"
            eval "${vegito_cmd} &"
            pids["Vegito-$i"]=$!
        fi
    done
fi

if [ "$role" == "writer" ] && [ "$k8s_mode" == "true" ]; then
    WRITER_HOME=./vegito

    vegito_cmd="$WRITER_HOME/vegito --v6d_ipc_socket $v6d_sock \
        --etcd_endpoint $etcd_endpoint --meta_prefix $etcd_prefix \
        --kafka_broker_list $kafka_server \
        --subgraph_num $subgraph_num --subgraph_id $subgraph_id"

    if $debug_writer; then
        echo "Debug Wrtier $subgraph_id: ${vegito_cmd} &"
    else
        echo "Start Writer $subgraph_id"
        eval "${vegito_cmd} &"
        pids["Vegito"]=$!
    fi
fi

echo "Process IDs:"
for key in "${!pids[@]}"; do
    echo "    $key: ${pids[$key]}"
done

echo "Role $role started."

if [ "$role" == "all" ]; then
    ./check_process.sh $v6d_sock "$(declare -p pids)" &

    sleep 2 # wait for output

    echo "GART started completely."
fi
