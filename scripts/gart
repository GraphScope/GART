#!/bin/bash

# Copyright 2020-2023 Alibaba Group Holding Limited.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

KAFKA_HOME=$KAFKA_HOME
MAXWELL_HOME=$MAXWELL_HOME

####################### Parse Arguments #######################
VALID_ARGS=$(getopt -o d:b:u:p:r:t:e:k:h? --long db-host:,db-name:,db-port:,user:,password:,rgmapping-file:,v6d-sock:,v6d-size:,use-debezium:,db-type:,enable-bulkload:,etcd-endpoint:,etcd-prefix:,kafka-server:,subgraph-num:,subgraph-id:,role:,start-slot:,num-slot:,k8s-mode:,rg-from-etcd:,help -- "$@")
if [[ $? -ne 0 ]]; then
    exit 1;
fi

db_host="127.0.0.1"
db_port=3306
db_name="ldbc"
user=
password=
rgmapping_file="schema/rgmapping-ldbc.yaml"
v6d_sock="/var/run/vineyard.sock"
v6d_size="750G"
etcd_endpoint="http://127.0.0.1:2379"
etcd_prefix="gart_meta_"
kafka_server="127.0.0.1:9092"
subgraph_num=1
use_debezium=1
db_type="mysql"
enable_bulkload=false
role="all"
start_slot=
num_slot=
rg_from_etcd=0
k8s_mode="no"
subgraph_id=0

set_port=false
eval set -- "$VALID_ARGS"
while [ : ]; do
  case "$1" in
    -d | --db-host)
        db_host=$2
        shift 2
        ;;
         --db-port)
        db_port=$2
        shift 2
        set_port=true
        ;;
    -b | --db-name)
        db_name=$2
        shift 2
        ;;
    -u | --user)
        user=$2
        shift 2
        ;;
    -p | --password)
        password=$2
        shift 2
        ;;
    -r | --rgmapping-file)
        rgmapping_file=$2
        shift 2
        ;;
         --v6d-sock)
        v6d_sock=$2
        shift 2
        ;;
         --v6d-size)
        v6d_size=$2
        shift 2
        ;;
        --use-debezium)
        use_debezium=$2
        shift 2
        ;;
         --db-type)
        db_type=$2
        shift 2
        ;;
        --enable-bulkload)
        enable_bulkload=$2
        shift 2
        ;;
    -e | --etcd-endpoint)
        etcd_endpoint=$2
        shift 2
        ;;
         --etcd-prefix)
        etcd_prefix=$2
        shift 2
        ;;
    -k | --kafka-server)
        kafka_server=$2
        shift 2
        ;;
         --subgraph-num)
        subgraph_num=$2
        shift 2
        ;;
         --subgraph-id)
        subgraph_id=$2
        shift 2
        ;;
         --role)
        role=$2
        shift 2
        ;;
         --start-slot)
        start_slot=$2
        shift 2
        ;;
         --num-slot)
        num_slot=$2
        shift 2
        ;;
         --rg-from-etcd)
        rg_from_etcd=$2
        shift 2
        ;;
         --k8s-mode)
        k8s_mode=$2
        shift 2
        ;;
    -h | --help | ?)
        echo "Usage: $0 [options]"
        echo "      --db-type:           type of data source: postgresql, mysql (default: postgresql)"
        echo "  -d, --db-host:           database host (default: 127.0.0.1)"
        echo "      --db-port:           database port (default: 3306 for MySQL, 5432 for PostgreSQL)"
        echo "  -b, --db-name:           database name (default: ldbc)"
        echo "  -u, --user:              database user"
        echo "  -p, --password:          database password"
        echo "  -r, --rgmapping-file:    rgmapping file path (default: schema/rgmapping-ldbc.yaml)"
        echo "      --v6d-sock:          vineyard socket path (default: /var/run/vineyard.sock)"
        echo "      --v6d-size:          vineyard size (default: 110G)"
        echo "      --use-debezium:      if use Debezium to parse txn logs (default: 1)"
        echo "      --enable-bulkload:   if enable bulkload (default: false)"
        echo "  -e, --etcd-endpoint:     etcd endpoint (default: http://127.0.0.1:2379)"
        echo "      --etcd-prefix:       etcd meta prefix (default: gart_meta_)"
        echo "  -k, --kafka-server:      kafka bootstrap server (default: 127.0.0.1:9092)"
        echo "      --subgraph-num:      number of sub graphs (default: 1)"
        echo "      --role:              the role of running this script: capturer, converter, writer or all (default: all)"
        echo "      --start-slot:        the start slot of subgraph on this machine"
        echo "      --num-slot:          the number of slots on this machine"
        echo "      --rg-from-etcd:      if read rg mapping from etcd (default: 0)"
        echo "      --k8s-mode:          if running in k8s mode (default: no)"
        echo "  -h, --help:              help"
        exit 0
        ;;
    --)
        shift;
        break
        ;;
  esac
done

# check file path
function make_absolute_path() {
  local path=$1
  if [[ ! $path = /* ]]; then
    path=$(readlink -f "$path" 2>/dev/null || pwd -P)
  fi
  echo "$path"
}

v6d_sock=$(make_absolute_path "$v6d_sock")
rgmapping_file=$(make_absolute_path "$rgmapping_file")

# set default port
if [ !$set_port ] && [ "$db_type" == "postgresql" ]; then
    db_port=5432
fi

if [ "$enable_bulkload" == 1 ]; then
    enable_bulkload=true
fi

if [ "$enable_bulkload" == 0 ]; then
    enable_bulkload=false
fi

# check arguments
if [ "$db_type" != "mysql" ] && [ "$db_type" != "postgresql" ]; then
    echo "Invalid value for 'db_type': $db_type"
    exit 1
fi

if [ "$use_debezium" == 0 ] && [ "$db_type" != "mysql" ]; then
    echo "Maxwell only supports MySQL"
    exit 1
fi

if [ "$role" != "all" ] && [ "$role" != "capturer" ] && [ "$role" != "converter" ] && [ "$role" != "writer" ]; then
    echo "Invalid value for 'role': $role"
    exit 1
fi

# check environment variables
if [ "$role" == "all" ] || [ "$role" == "capturer" ]; then
    unset=false
    if [ -n "$KAFKA_HOME" ]; then
        echo "    KAFKA_HOME: $KAFKA_HOME"
    else
        echo "KAFKA_HOME is empty, please set the environment variable KAFKA_HOME"
        unset=true
    fi


    if [ "$use_debezium" == 0 ]; then
        if [ -n "$MAXWELL_HOME" ]; then
            echo "    MAXWELL_HOME: $MAXWELL_HOME"
        else
            echo "MAXWELL_HOME is empty, please set the environment variable MAXWELL_HOME"
            unset=true
        fi
    fi

    if [ $unset == true ]; then
        exit 1
    fi
fi

if [ "$role" == "all" ] || [ "$role" == "writer" ]; then
    if [ "$role" == "all" ]; then
        start_slot=0
        num_slot=$subgraph_num
    fi
    if [ "$role" == "writer" ]; then
        if [ ! -n "$start_slot" ] && [ ! -n "$num_slot" ]; then
            start_slot=0
            num_slot=$subgraph_num
        elif [ -n "$start_slot" ] && [ ! -n "$num_slot" ]; then
            echo "Please set both start-slot and num-slot"
            exit 1
        elif [ ! -n "$start_slot" ] && [ -n "$num_slot" ]; then
            echo "Please set both start-slot and num-slot"
            exit 1
        else
            echo "    Run Writer as given slot info"
        fi
    fi
    echo "    Start slot: $start_slot"
    echo "    Number of slots: $num_slot"
fi

echo "Arguments:"
echo "    db-type: $db_type"
echo "    db-host: $db_host"
echo "    db-port: $db_port"
echo "    db-name: $db_name"
echo "    user: $user"
echo "    password: $password"
echo "    rgmapping-file: $rgmapping_file"
echo "    v6d-sock: $v6d_sock"
echo "    v6d-size: $v6d_size"
echo "    use-debezium: $use_debezium"
echo "    enable-bulkload: $enable_bulkload"
echo "    etcd-endpoint: $etcd_endpoint"
echo "    etcd-prefix: $etcd_prefix"
echo "    kafka-server: $kafka_server"
echo "    subgraph-num: $subgraph_num"
echo "    start-slot: $start_slot"
echo "    num-slot: $num_slot"
echo "    role: $role"

if [ "$role" == "all" ]; then
    ##################### Stop Previous GART ######################
    echo "Stop previous GART"
    ./stop-gart --kill-v6d-sock $v6d_sock

    ####################### Clean Etcd #######################
    echo "Clean etcd"
    etcdctl --endpoints=$etcd_endpoint del --prefix $etcd_prefix > /dev/null 2>&1
fi

declare -A pids     # array to store pids and comments

####################### Vineyard #######################
if [ "$role" == "all" ] || [ "$role" == "writer" ]; then
    echo "Start Vineyard"
    if ! pgrep -f "vineyardd .* $v6d_sock" > /dev/null 2>&1; then
        if [ -e "$v6d_sock" ]; then
            echo "Remove existing vineyard socket $v6d_sock"
            rm $v6d_sock
        fi
        echo "Start to launch vineyardd on $v6d_sock"
        # TODO: etcd_cmd user for PostgreSQL Extension
        vineyardd --socket $v6d_sock --size $v6d_size --etcd_endpoint $etcd_endpoint  --norpc > /dev/null 2>&1 &
        pids["Vineyard"]=$!
        sleep 5
        if [ ! -e "$v6d_sock" ] || [ ! -S "$v6d_sock" ]; then
            echo "Failed to launch vineyardd"
            exit 1
        fi
    fi
fi

####################### Etcd #######################
if [ "$k8s_mode" == "no" ] && { [ "$role" == "capturer" ] || [ "$role" == "converter" ]; }; then
    echo "Start to launch Etcd by role $role"
    if ! pgrep -f "etcd .*$etcd_endpoint" > /dev/null 2>&1; then
        echo "Start to launch etcd on $etcd_endpoint"
        export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
        etcd_status=$(
        ./scripts/launch_etcd.py --etcd_endpoint $etcd_endpoint
        )
        if [ $etcd_status -eq 1 ]; then
            echo "Etcd is launched successfully"
        else
            echo "Failed to launch etcd"
            exit 1
        fi
    else
        echo "Etcd is already running"
    fi
fi


####################### Extract Schema #######################
if [ "$role" == "all" ] || [ "$role" == "capturer" ] || { [ "$k8s_mode" == "yes" ] && [ "$role" == "converter" ]; }; then
    echo "Start extracting schema"
    export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
    num_row=$(
    ./scripts/extract_table_schema.py \
        --host $db_host --port $db_port --db $db_name \
        --user $user --password $password --db_type $db_type\
        --rgmapping_file $rgmapping_file --etcd_endpoint $etcd_endpoint \
        --etcd_prefix $etcd_prefix --rg_mapping_from_etcd $rg_from_etcd
    )
    if [ $num_row -eq -1 ]; then
        echo "Failed to extract schema from database, please check the status of database and database info you provide."
        exit 1
    elif [ $num_row -eq 0 ] && $enable_bulkload; then
        echo "No tuples found in the database, skip bulk load"
        enable_bulkload=false
    fi
fi

################### Bulk Load Initialize ######################
if [ "$role" == "all" ] || [ "$role" == "capturer" ]; then
    if [ "$use_debezium" == 1 ] && $enable_bulkload; then
        rm /tmp/connect.offsets 1 > /dev/null 2>&1
        echo "Remove /tmp/connect.offsets for bulk load"
    fi
fi

####################### Capturer: Zookeeper and Kafka #######################
if [ "$role" == "all" ] || [ "$role" == "capturer" ]; then
    KAFKA_BIN=$KAFKA_HOME/bin
    KAFKA_CONFIG=$KAFKA_HOME/config
    KAFKA_LOG=$KAFKA_HOME/logs/kafkaServer.out

    # write kafka config according to graph schema
    ./scripts/update_kafka_config_file.py --etcd_endpoint $etcd_endpoint --etcd_prefix $etcd_prefix \
                                        --kafka_endpoint $kafka_server --db_type $db_type --db_host $db_host --db_port $db_port \
                                        --db_user $user --db_password $password --db_name $db_name --enable_bulkload $enable_bulkload

    echo "Start Zookeeper and Kafka"
    $KAFKA_BIN/zookeeper-server-start.sh -daemon $KAFKA_CONFIG/zookeeper.properties
    # pids["Zookeeper"]=$!
    sleep 20
    # sleep 20 to avoid https://stackoverflow.com/questions/39759071/error-while-starting-kafka-broker

    # Checking if the Zookeeper process is running
    if ps -ef | grep -v grep | grep zookeeper.server; then
        echo "Zookeeper process is running."
    else
        echo "Zookeeper process is NOT running. Wait for retrying."
    fi

    $KAFKA_BIN/kafka-server-start.sh -daemon $KAFKA_CONFIG/server.properties

    # pids["Kafka"]=$!
    sleep 8
    # check if Kafka is started
    if grep -q "started" $KAFKA_LOG; then
        echo "Kafka log shows successful startup."
    else
        echo "Kafka log does not indicate successful startup. Please check $KAFKA_LOG for details. Wait for retrying."
    fi


    # check Kafka failure
    for i in {1..3}
    do
        if grep -q "ERROR" $KAFKA_LOG; then
            if [ $i -ne 1 ]; then
                echo "File $KAFKA_LOG contains ERROR, waiting for cleanning"
                sleep 10
            fi
            $KAFKA_BIN/zookeeper-server-start.sh -daemon $KAFKA_CONFIG/zookeeper.properties
            sleep 3
            # Checking if the Zookeeper process is running
            if ps -ef | grep -v grep | grep zookeeper.server; then
                echo "Zookeeper process is running."
            else
                echo "Zookeeper process is NOT running. Wait for retrying."
            fi


            $KAFKA_BIN/kafka-server-start.sh -daemon $KAFKA_CONFIG/server.properties
            sleep 5
            if grep -q "started" $KAFKA_LOG; then
                echo "Kafka log shows successful startup."
            else
                echo "Kafka log does not indicate successful startup. Please check $KAFKA_LOG for details. Wait for retrying."
            fi

        else
            break
        fi
        if [ $i -eq 3 ]; then
            echo "Kafka: Reached max attempts, ERROR found"
            ./stop-gart --kill-v6d-sock $v6d_sock --is-abnormal
            exit 1
        fi
    done

    echo "    Clean topics: binlog & unified_log"
    $KAFKA_BIN/kafka-topics.sh --delete --topic 'binlog.*' --bootstrap-server 127.0.0.1:9092 > /dev/null 2>&1
    $KAFKA_BIN/kafka-topics.sh --delete --topic unified_log --bootstrap-server 127.0.0.1:9092 > /dev/null 2>&1

    sleep 2

    #TODO: hard code: replication-factor

    echo "    Create topic: binlog"
    $KAFKA_BIN/kafka-topics.sh --create --topic binlog --bootstrap-server 127.0.0.1:9092 --partitions 1 --replication-factor 1 > /dev/null 2>&1

    echo "    Create topic: unified_log"
    $KAFKA_BIN/kafka-topics.sh --create --topic unified_log --bootstrap-server 127.0.0.1:9092 --partitions 1 --replication-factor 1 > /dev/null 2>&1
    # $KAFKA_BIN/kafka-topics.sh --bootstrap-server 127.0.0.1:9092 --list
fi


####################### Capturer: Maxwell #######################
if [ "$role" == "all" ] || [ "$role" == "capturer" ]; then
    if [ "$use_debezium" == 0 ]; then
        MAXWELL_BIN=$MAXWELL_HOME/bin

        echo "Start Maxwell"
        $MAXWELL_BIN/maxwell --host=$db_host --user=$user --password=$password --producer=kafka --kafka.bootstrap.servers=127.0.0.1:9092 --kafka_topic=binlog > /dev/null 2>&1 &

        pids["Maxwell"]=$!
        sleep 3
        process_count=$(
            ps aux | grep '[m]axwell.Maxwell' | wc -l | awk '{print $1}'
        )
        if [ $process_count -gt 0 ]; then
            export ETCDCTL_API=3
            etcd_prefix=$etcd_prefix
            etcd_key=$etcd_prefix"capturer_is_up"
            etcdctl --endpoints=$etcd_endpoint put $etcd_key "True"
        fi
    fi
fi

####################### Capturer: Debezium #######################
if [ "$role" == "all" ] || [ "$role" == "capturer" ]; then
# TODO(wanglei): add distributed deployment of debezium
    if [ "$use_debezium" == 1 ]; then
        unset CLASSPATH
        echo "Start Debezium"
        if [ "$db_type" == "mysql" ]; then
            echo "    Start Debezium connector for MySQL"
            $KAFKA_BIN/connect-standalone.sh $KAFKA_CONFIG/connect-standalone.properties $KAFKA_CONFIG/connect-debezium-mysql.properties > /dev/null 2>&1 &
        elif [ "$db_type" == "postgresql" ]; then
            echo "    Start Debezium connector for PostgreSQL"
            $KAFKA_BIN/connect-standalone.sh $KAFKA_CONFIG/connect-standalone.properties $KAFKA_CONFIG/connect-debezium-postgresql.properties > /dev/null 2>&1 &
        fi
        pids["Debezium"]=$!
        sleep 5
        process_count=$(
            ps aux | grep '[d]ebezium-api' | wc -l | awk '{print $1}'
        )
        if [ $process_count -gt 0 ]; then
            export ETCDCTL_API=3
            etcd_prefix=$etcd_prefix
            etcd_key=$etcd_prefix"capturer_is_up"
            etcdctl --endpoints=$etcd_endpoint put $etcd_key "True"
        fi
    fi
fi

####################### Converter #######################
if [ "$role" == "all" ] || [ "$role" == "converter" ]; then
    CONVENTER_HOME=./converter
    echo "Start Converter"
    # For bool flags, = is necessary,
    # since --enable_bulkload will be parsed as --enable_bulkload=true,
    # and --no_enable_bulkload will be parsed as --enable_bulkload=false
    if [ "$use_debezium" == 1 ]; then
        echo "    Use Debezium converter"
        $CONVENTER_HOME/binlog_convert_debezium \
            --etcd_endpoint $etcd_endpoint \
            --etcd_prefix $etcd_prefix \
            --read_kafka_broker_list $kafka_server \
            --write_kafka_broker_list $kafka_server \
            --subgraph_num $subgraph_num --logs_per_epoch 10000 \
            --enable_bulkload=$enable_bulkload &
    else
        echo "    Use Maxwell converter"
        $CONVENTER_HOME/binlog_convert_maxwell  --etcd_endpoint $etcd_endpoint \
            --etcd_prefix $etcd_prefix \
            --read_kafka_broker_list $kafka_server \
            --write_kafka_broker_list $kafka_server \
            --subgraph_num $subgraph_num --logs_per_epoch 10000 &
    fi
    pids["Converter"]=$!
    sleep 2

fi

####################### Writer (VEGITO) #######################
if [[ "$role" == "all" ]] || { [[ "$role" == "writer" ]] && [[ "$k8s_mode" == "no" ]]; }; then
    WRITER_HOME=./vegito

    echo "Start Writer"

    for ((i=$start_slot; i<$start_slot + $num_slot; i++)); do
        $WRITER_HOME/vegito --v6d_ipc_socket $v6d_sock \
        --etcd_endpoint $etcd_endpoint --meta_prefix $etcd_prefix \
        --kafka_broker_list $kafka_server \
        --subgraph_num $subgraph_num --subgraph_id $i &
        pids["Vegito-$i"]=$!
    done
fi

if [ "$role" == "writer" ] && [ "$k8s_mode" == "yes" ]; then
    WRITER_HOME=./vegito

    echo "Start Writer $subgraph_id"


    $WRITER_HOME/vegito --v6d_ipc_socket $v6d_sock \
    --etcd_endpoint $etcd_endpoint --meta_prefix $etcd_prefix \
    --kafka_broker_list $kafka_server \
    --subgraph_num $subgraph_num --subgraph_id $subgraph_id &
    pids["Vegito"]=$!
fi

echo "Process IDs:"
for key in "${!pids[@]}"; do
    echo "    $key: ${pids[$key]}"
done

echo "Role $role started."

if [ "$role" == "all" ]; then
    ./check_process.sh $v6d_sock "$(declare -p pids)" &

    sleep 2 # wait for output

    echo "GART started completely."
fi
